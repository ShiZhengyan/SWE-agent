description: Train Qwen 32B Model using torch tune
environment:
  image: rocm6.4_ubuntu24.04_py3.12_pytorch2.6.0_flashattn_transformers:latest
  registry: msrmtlacr.azurecr.io
  env:
    WANDB_API_KEY: $WANDB_API_KEY
    WANDB_BASE_URL: $WANDB_BASE_URL
    WANDB_DISABLED: "true" # disable wandb
    WANDB_MODE: disabled
    HF_HUB_READ_TIMEOUT: 100
    NCCL_TIMEOUT: 1800
    NCCL_BLOCKING_WAIT: "1"
    TORCH_NCCL_ASYNC_ERROR_HANDLING: "1"
  setup:
    - sudo apt update && sudo apt install -y git python3-apt

code:
  local_dir: $CONFIG_DIR/../..

jobs:
- name: torch_run_32B_1r1m
  submit_args:
    env:
      _AZUREML_SINGULARITY_JOB_UAI: $AZUREML_SINGULARITY_JOB_UAI
  sku: G8-MI300X
  process_count_per_node: 1 # 8 # 4 GPUs. 
  command:
  - cat /opt/rocm/.info/version
  - rocm-smi
  - rocm-smi --showdriverversion
  - echo $$PATH
  - echo $$LD_LIBRARY_PATH
  - echo $$AMLT_OUTPUT_DIR
  - env

  - export PATH="$$HOME/.local/bin:$$PATH"
  - python -m pip install --upgrade pip
  - python -m pip install ipython ipdb
  - pip install wandb
  - pip install torchao
  - git clone --depth 1 https://github.com/ShiZhengyan/torchtune-0.6.1.git
  - cd torchtune-0.6.1
  - pip install -e .
  - cd ..
  - |
    tune download Qwen/Qwen2.5-Coder-32B-Instruct \
      --output-dir llm-weights/Qwen/Qwen2.5-Coder-32B-Instruct \
      --ignore-patterns "original/consolidated.00.pth"
  # - python -c "from datasets import load_dataset; ds=load_dataset('SWE-bench/SWE-smith-trajectories', split='train'); ds.to_json('datasets/swe-smith-trajectories.jsonl')"

  - mkdir -p ckpt
  - |
    tune run --nnodes 1 --nproc_per_node 8 agent_sft_distributed \
      --config ${CONFIG_FILE} \
      $EXTRA_ARGS output_dir=./ckpt && cp -r ./ckpt/* $$AMLT_OUTPUT_DIR
